{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "Dl5zjs1_GqNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOnNC7SBZ4YB",
        "outputId": "6b8ab8e2-3ea9-49aa-e445-4bf45f9bfe61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "from torchinfo import summary\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "PRYIeQA3rHk2",
        "execution": {
          "iopub.status.busy": "2023-09-05T13:35:15.01263Z",
          "iopub.execute_input": "2023-09-05T13:35:15.013135Z",
          "iopub.status.idle": "2023-09-05T13:35:23.74943Z",
          "shell.execute_reply.started": "2023-09-05T13:35:15.013095Z",
          "shell.execute_reply": "2023-09-05T13:35:23.748417Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqUJURrXZwiC",
        "outputId": "107e413e-4750-4726-cb20-ee75ac382b93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Visualization"
      ],
      "metadata": {
        "id": "aIcyaJm2TPg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/download')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvV1eImWXN6j",
        "outputId": "3d9722de-927f-455b-9f6c-0a9c9a066920"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/download/MyDrive/1-09-1-20.csv\")\n",
        "print(df.shape)\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "xpQnLOr7nGuu",
        "execution": {
          "iopub.status.busy": "2023-09-05T09:38:46.654854Z",
          "iopub.execute_input": "2023-09-05T09:38:46.655547Z",
          "iopub.status.idle": "2023-09-05T09:39:28.130339Z",
          "shell.execute_reply.started": "2023-09-05T09:38:46.655516Z",
          "shell.execute_reply": "2023-09-05T09:39:28.129321Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "b3001215-03a1-409b-c453-d24bda4e2835"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3730870, 43)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0              0                    1        2      3  \\\n",
              "3730865     3730865  1674238247671  2023-01-20 18:10:47  21337.6  0.167   \n",
              "3730866     3730866  1674238247921  2023-01-20 18:10:47  21337.5  0.108   \n",
              "3730867     3730867  1674238248172  2023-01-20 18:10:48  21337.4  0.891   \n",
              "3730868     3730868  1674238248422  2023-01-20 18:10:48  21337.4  2.456   \n",
              "3730869     3730869  1674238248672  2023-01-20 18:10:48  21337.4  2.513   \n",
              "\n",
              "               4      5        6      7        8  ...       32     33  \\\n",
              "3730865  21337.5  0.100  21337.4  0.014  21336.9  ...  21338.2  0.022   \n",
              "3730866  21337.4  0.014  21336.9  0.257  21336.8  ...  21338.2  0.022   \n",
              "3730867  21337.2  0.552  21337.1  1.095  21336.9  ...  21338.1  0.002   \n",
              "3730868  21337.3  1.149  21337.2  0.002  21336.9  ...  21338.1  0.002   \n",
              "3730869  21337.3  1.149  21337.2  0.002  21336.9  ...  21338.1  0.002   \n",
              "\n",
              "              34     35       36     37       38     39       40     41  \n",
              "3730865  21338.3  0.028  21338.4  0.235  21338.5  1.657  21338.6  0.234  \n",
              "3730866  21338.3  0.036  21338.4  0.236  21338.5  1.657  21338.6  0.235  \n",
              "3730867  21338.2  0.048  21338.3  0.036  21338.4  0.001  21338.5  1.658  \n",
              "3730868  21338.2  0.048  21338.3  0.036  21338.4  0.001  21338.5  1.658  \n",
              "3730869  21338.2  0.048  21338.3  0.036  21338.4  0.001  21338.5  1.047  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f197c6c-dbd9-4960-8379-e23b110be028\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3730865</th>\n",
              "      <td>3730865</td>\n",
              "      <td>1674238247671</td>\n",
              "      <td>2023-01-20 18:10:47</td>\n",
              "      <td>21337.6</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21337.5</td>\n",
              "      <td>0.100</td>\n",
              "      <td>21337.4</td>\n",
              "      <td>0.014</td>\n",
              "      <td>21336.9</td>\n",
              "      <td>...</td>\n",
              "      <td>21338.2</td>\n",
              "      <td>0.022</td>\n",
              "      <td>21338.3</td>\n",
              "      <td>0.028</td>\n",
              "      <td>21338.4</td>\n",
              "      <td>0.235</td>\n",
              "      <td>21338.5</td>\n",
              "      <td>1.657</td>\n",
              "      <td>21338.6</td>\n",
              "      <td>0.234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3730866</th>\n",
              "      <td>3730866</td>\n",
              "      <td>1674238247921</td>\n",
              "      <td>2023-01-20 18:10:47</td>\n",
              "      <td>21337.5</td>\n",
              "      <td>0.108</td>\n",
              "      <td>21337.4</td>\n",
              "      <td>0.014</td>\n",
              "      <td>21336.9</td>\n",
              "      <td>0.257</td>\n",
              "      <td>21336.8</td>\n",
              "      <td>...</td>\n",
              "      <td>21338.2</td>\n",
              "      <td>0.022</td>\n",
              "      <td>21338.3</td>\n",
              "      <td>0.036</td>\n",
              "      <td>21338.4</td>\n",
              "      <td>0.236</td>\n",
              "      <td>21338.5</td>\n",
              "      <td>1.657</td>\n",
              "      <td>21338.6</td>\n",
              "      <td>0.235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3730867</th>\n",
              "      <td>3730867</td>\n",
              "      <td>1674238248172</td>\n",
              "      <td>2023-01-20 18:10:48</td>\n",
              "      <td>21337.4</td>\n",
              "      <td>0.891</td>\n",
              "      <td>21337.2</td>\n",
              "      <td>0.552</td>\n",
              "      <td>21337.1</td>\n",
              "      <td>1.095</td>\n",
              "      <td>21336.9</td>\n",
              "      <td>...</td>\n",
              "      <td>21338.1</td>\n",
              "      <td>0.002</td>\n",
              "      <td>21338.2</td>\n",
              "      <td>0.048</td>\n",
              "      <td>21338.3</td>\n",
              "      <td>0.036</td>\n",
              "      <td>21338.4</td>\n",
              "      <td>0.001</td>\n",
              "      <td>21338.5</td>\n",
              "      <td>1.658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3730868</th>\n",
              "      <td>3730868</td>\n",
              "      <td>1674238248422</td>\n",
              "      <td>2023-01-20 18:10:48</td>\n",
              "      <td>21337.4</td>\n",
              "      <td>2.456</td>\n",
              "      <td>21337.3</td>\n",
              "      <td>1.149</td>\n",
              "      <td>21337.2</td>\n",
              "      <td>0.002</td>\n",
              "      <td>21336.9</td>\n",
              "      <td>...</td>\n",
              "      <td>21338.1</td>\n",
              "      <td>0.002</td>\n",
              "      <td>21338.2</td>\n",
              "      <td>0.048</td>\n",
              "      <td>21338.3</td>\n",
              "      <td>0.036</td>\n",
              "      <td>21338.4</td>\n",
              "      <td>0.001</td>\n",
              "      <td>21338.5</td>\n",
              "      <td>1.658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3730869</th>\n",
              "      <td>3730869</td>\n",
              "      <td>1674238248672</td>\n",
              "      <td>2023-01-20 18:10:48</td>\n",
              "      <td>21337.4</td>\n",
              "      <td>2.513</td>\n",
              "      <td>21337.3</td>\n",
              "      <td>1.149</td>\n",
              "      <td>21337.2</td>\n",
              "      <td>0.002</td>\n",
              "      <td>21336.9</td>\n",
              "      <td>...</td>\n",
              "      <td>21338.1</td>\n",
              "      <td>0.002</td>\n",
              "      <td>21338.2</td>\n",
              "      <td>0.048</td>\n",
              "      <td>21338.3</td>\n",
              "      <td>0.036</td>\n",
              "      <td>21338.4</td>\n",
              "      <td>0.001</td>\n",
              "      <td>21338.5</td>\n",
              "      <td>1.047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f197c6c-dbd9-4960-8379-e23b110be028')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f197c6c-dbd9-4960-8379-e23b110be028 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f197c6c-dbd9-4960-8379-e23b110be028');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f166f07-feb9-41c5-9b20-9becf423d1f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f166f07-feb9-41c5-9b20-9becf423d1f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f166f07-feb9-41c5-9b20-9becf423d1f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_columns = [\n",
        "    'index', 'timestamp', 'time', 'bid1', 'bid1vol', 'bid2', 'bid2vol',\n",
        "    'bid3', 'bid3vol', 'bid4', 'bid4vol', 'bid5', 'bid5vol',\n",
        "    'bid6', 'bid6vol', 'bid7', 'bid7vol', 'bid8', 'bid8vol',\n",
        "    'bid9', 'bid9vol', 'bid10', 'bid10vol', 'ask1', 'ask1vol',\n",
        "    'ask2', 'ask2vol', 'ask3', 'ask3vol', 'ask4', 'ask4vol',\n",
        "    'ask5', 'ask5vol', 'ask6', 'ask6vol', 'ask7', 'ask7vol',\n",
        "    'ask8', 'ask8vol', 'ask9', 'ask9vol', 'ask10', 'ask10vol'\n",
        "]\n",
        "df.columns = new_columns\n",
        "df['mid'] = 0.5*(df['bid1'] + df['ask1'])\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "8YKXtLEqzNCY",
        "execution": {
          "iopub.status.busy": "2023-09-05T09:39:28.134749Z",
          "iopub.execute_input": "2023-09-05T09:39:28.135675Z",
          "iopub.status.idle": "2023-09-05T09:39:29.460348Z",
          "shell.execute_reply.started": "2023-09-05T09:39:28.135637Z",
          "shell.execute_reply": "2023-09-05T09:39:29.459143Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6af8d2-f871-472f-a195-9be8c366529e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   index      timestamp                 time     bid1  bid1vol     bid2  \\\n",
            "0      0  1673302660926  2023-01-09 22:17:40  17181.6   23.371  17181.5   \n",
            "1      1  1673302661177  2023-01-09 22:17:41  17181.6   24.232  17181.5   \n",
            "2      2  1673302661427  2023-01-09 22:17:41  17181.6   24.403  17181.5   \n",
            "3      3  1673302661678  2023-01-09 22:17:41  17181.6   24.874  17181.5   \n",
            "4      4  1673302661928  2023-01-09 22:17:41  17181.6   24.403  17181.5   \n",
            "\n",
            "   bid2vol     bid3  bid3vol     bid4  ...  ask6vol     ask7  ask7vol  \\\n",
            "0    0.746  17181.4    5.428  17181.2  ...    5.168  17182.3     0.02   \n",
            "1    0.694  17181.4    5.428  17181.2  ...    6.043  17182.3     0.02   \n",
            "2    0.694  17181.4    5.428  17181.2  ...    6.043  17182.3     0.02   \n",
            "3    0.694  17181.4    5.428  17181.2  ...    6.043  17182.3     0.02   \n",
            "4    0.694  17181.4    5.428  17181.2  ...    6.043  17182.3     0.02   \n",
            "\n",
            "      ask8  ask8vol     ask9  ask9vol    ask10  ask10vol       mid  \n",
            "0  17182.4    6.692  17182.5    1.904  17182.6     2.546  17181.65  \n",
            "1  17182.4    6.001  17182.5    1.869  17182.6     2.105  17181.65  \n",
            "2  17182.4    6.012  17182.5    1.869  17182.6     2.713  17181.65  \n",
            "3  17182.4    6.001  17182.5    2.570  17182.6     2.613  17181.65  \n",
            "4  17182.4    6.001  17182.5    2.589  17182.6     2.591  17181.65  \n",
            "\n",
            "[5 rows x 44 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interval_set = 5 * 1000 #predicted timeslot\n",
        "df['timestamp_predict'] = df['timestamp'] + interval_set\n",
        "df['mom'] = df['mid']\n",
        "# Use numpy to find the closest indices efficiently\n",
        "timestamps = df['timestamp'].values\n",
        "predicted_timestamps = df['timestamp_predict'].values\n",
        "closest_indices = np.searchsorted(timestamps, predicted_timestamps)\n",
        "\n",
        "for ind, row in df.iterrows():\n",
        "    if ind == len(df) - 1:\n",
        "        df.at[ind, 'mom'] = 0\n",
        "        break\n",
        "\n",
        "    # Find the closest timestamp index\n",
        "    closest_index = closest_indices[ind]\n",
        "    if closest_index >= len(df):\n",
        "        closest_index = len(df) - 1\n",
        "\n",
        "    if row['mid'] < df.loc[closest_index, 'mid']:\n",
        "        df.at[ind, 'mom'] = 2\n",
        "    if row['mid'] > df.loc[closest_index, 'mid']:\n",
        "        df.at[ind, 'mom'] = 0\n",
        "    if row['mid'] == df.loc[closest_index, 'mid']:\n",
        "        df.at[ind, 'mom'] = 1\n"
      ],
      "metadata": {
        "id": "Cuoj1Qlmi3KE",
        "execution": {
          "iopub.status.busy": "2023-09-05T09:39:29.463127Z",
          "iopub.execute_input": "2023-09-05T09:39:29.463834Z",
          "iopub.status.idle": "2023-09-05T09:39:29.597715Z",
          "shell.execute_reply.started": "2023-09-05T09:39:29.463797Z",
          "shell.execute_reply": "2023-09-05T09:39:29.596411Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['mom'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "SdW67np_yPv5",
        "outputId": "09b0a1fa-c0d1-4490-93e3-d450921d899a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    3.730870e+06\n",
              "mean     9.959235e-01\n",
              "std      8.370131e-01\n",
              "min      0.000000e+00\n",
              "25%      0.000000e+00\n",
              "50%      1.000000e+00\n",
              "75%      2.000000e+00\n",
              "max      2.000000e+00\n",
              "Name: mom, dtype: float64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = df['timestamp'].tolist()[-1] - interval_set\n",
        "df = df[df['timestamp'] <= end_time]"
      ],
      "metadata": {
        "id": "6iTjskaKC5iE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:len(df)//3]\n",
        "leng = len(df)\n",
        "print(leng)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1LFUz3WDN-H",
        "outputId": "7db4fc34-735e-4272-b6ed-36c78c449d5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1243616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_order = [\n",
        "    'bid1', 'bid1vol', 'ask1', 'ask1vol',\n",
        "    'bid2', 'bid2vol', 'ask2', 'ask2vol',\n",
        "    'bid3', 'bid3vol', 'ask3', 'ask3vol',\n",
        "    'bid4', 'bid4vol', 'ask4', 'ask4vol',\n",
        "    'bid5', 'bid5vol', 'ask5', 'ask5vol',\n",
        "    'bid6', 'bid6vol', 'ask6', 'ask6vol',\n",
        "    'bid7', 'bid7vol', 'ask7', 'ask7vol',\n",
        "    'bid8', 'bid8vol', 'ask8', 'ask8vol',\n",
        "    'bid9', 'bid9vol', 'ask9', 'ask9vol',\n",
        "    'bid10', 'bid10vol', 'ask10', 'ask10vol'\n",
        "]\n",
        "\n",
        "dataset_ordered = df[columns_order]\n",
        "target_ordered = df['mom']"
      ],
      "metadata": {
        "id": "lPsNDHsWz6ul"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSa6cwGZDhfW",
        "outputId": "645e906b-5bdb-4e59-d87a-f04fa1bd3826"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(data, targets, T):\n",
        "    time_dataset = []\n",
        "    time_targets = []\n",
        "    for i in range(T, len(data)):\n",
        "        cur = data[i-T:i].values\n",
        "        time_dataset.append(cur)\n",
        "        time_targets.append(targets[i])\n",
        "    return time_dataset, time_targets\n",
        "\n",
        "# Preparing the dataset\n",
        "T = 100  #  window size\n",
        "time_dataset, time_targets = make_dataset(dataset_ordered, target_ordered, T)"
      ],
      "metadata": {
        "id": "8OtZazlo39LB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset_ordered\n",
        "gc.collect()\n",
        "\n",
        "del target_ordered\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujJGfwyJDnCp",
        "outputId": "0ce06cb9-171a-4a79-8b14-ac4fe6a9dd3a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(data.Dataset):\n",
        "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
        "    def __init__(self, time_dataset, time_targets, T):\n",
        "        \"\"\"Initialization\"\"\"\n",
        "        self.T = T\n",
        "        x, y = np.array(time_dataset), np.array(time_targets)\n",
        "        self.length = len(x)\n",
        "        x = torch.from_numpy(x)\n",
        "        self.x = torch.unsqueeze(x, 1)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the total number of samples\"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generates samples of data\"\"\"\n",
        "        return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "eYFlXq3j4Pqz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(time_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMKmN9aP4Tam",
        "outputId": "577a01cc-9f28-4409-820a-57e13818880e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_index_train = int(leng * 0.7)\n",
        "split_index_val = int(leng * 0.8)\n",
        "\n",
        "\n",
        "time_dataset_train = time_dataset[:split_index_train]\n",
        "time_targets_train = time_targets[:split_index_train]\n",
        "time_dataset_val = time_dataset[split_index_train:split_index_val]\n",
        "time_targets_val = time_targets[split_index_train:split_index_val]\n",
        "time_dataset_test = time_dataset[split_index_val:]\n",
        "time_targets_test = time_targets[split_index_val:]"
      ],
      "metadata": {
        "id": "HHK5fi3b4Yq-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del time_dataset\n",
        "gc.collect()\n",
        "\n",
        "del time_targets\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9umPvsmDEz1z",
        "outputId": "5e78746b-6fd0-49c3-9ae1-f01e49bedcb3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "dataset_train = Dataset(time_dataset_train, time_targets_train, 100)\n",
        "print('here0')\n",
        "dataset_val = Dataset(time_dataset_val, time_targets_val, 100)\n",
        "print('here1')\n",
        "dataset_test = Dataset(time_dataset_test, time_targets_test, 100)\n",
        "print('here2')\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
        "print('here3')\n",
        "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(dataset_train.x.shape, dataset_train.y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QYd57ih7f1T",
        "outputId": "96d62e63-ca91-4d51-c750-b1cab06f9c8e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here0\n",
            "here1\n",
            "here2\n",
            "here3\n",
            "torch.Size([870531, 1, 100, 40]) torch.Size([870531])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(dataset_train, '/content/download/MyDrive/download/dataset_train.pt')\n",
        "torch.save(dataset_val, '/content/download/MyDrive/download/dataset_val.pt')\n",
        "torch.save(dataset_test, '/content/download/MyDrive/download/dataset_test.pt')"
      ],
      "metadata": {
        "id": "f55o47rJzXyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
        "for x, y in tmp_loader:\n",
        "    print(x)\n",
        "    print(y)\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtHUnFdP7jSE",
        "outputId": "c7a65379-eec2-4ea4-93b1-a1ca1534a79e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1.7181e+04, 4.5305e+01, 1.7181e+04,  ..., 7.0300e-01,\n",
            "           1.7182e+04, 1.3100e-01],\n",
            "          [1.7181e+04, 1.6076e+01, 1.7181e+04,  ..., 9.3300e-01,\n",
            "           1.7182e+04, 4.9010e+00],\n",
            "          [1.7181e+04, 1.4175e+01, 1.7181e+04,  ..., 8.7300e-01,\n",
            "           1.7182e+04, 4.9010e+00],\n",
            "          ...,\n",
            "          [1.7170e+04, 2.8713e+01, 1.7170e+04,  ..., 2.1270e+00,\n",
            "           1.7171e+04, 9.0100e-01],\n",
            "          [1.7170e+04, 3.5235e+01, 1.7170e+04,  ..., 2.1270e+00,\n",
            "           1.7171e+04, 9.0100e-01],\n",
            "          [1.7170e+04, 3.7121e+01, 1.7170e+04,  ..., 4.6880e+00,\n",
            "           1.7171e+04, 9.0100e-01]]]], dtype=torch.float64)\n",
            "tensor([2.], dtype=torch.float64)\n",
            "torch.Size([1, 1, 100, 40]) torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training DeepLOB\n"
      ],
      "metadata": {
        "id": "Uk7u9ZBqGk__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class deeplob(nn.Module):\n",
        "    def __init__(self, y_len):\n",
        "        super().__init__()\n",
        "        self.y_len = y_len\n",
        "\n",
        "        # convolution blocks\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "#             nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "\n",
        "        # inception moduels\n",
        "        self.inp1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp3 = nn.Sequential(\n",
        "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "\n",
        "        # lstm layers\n",
        "        self.lstm = nn.LSTM(input_size=192, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.fc1 = nn.Linear(64, self.y_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # h0: (number of hidden layers, batch size, hidden size)\n",
        "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
        "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "\n",
        "        x_inp1 = self.inp1(x)\n",
        "        x_inp2 = self.inp2(x)\n",
        "        x_inp3 = self.inp3(x)\n",
        "\n",
        "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
        "\n",
        "#         x = torch.transpose(x, 1, 2)\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
        "\n",
        "        x, _ = self.lstm(x, (h0, c0))\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc1(x)\n",
        "        forecast_y = torch.softmax(x, dim=1)\n",
        "\n",
        "        return forecast_y"
      ],
      "metadata": {
        "id": "6P9hJhLj43zN",
        "execution": {
          "iopub.status.busy": "2023-09-05T09:39:36.981789Z",
          "iopub.execute_input": "2023-09-05T09:39:36.982179Z",
          "iopub.status.idle": "2023-09-05T09:39:37.000775Z",
          "shell.execute_reply.started": "2023-09-05T09:39:36.982143Z",
          "shell.execute_reply": "2023-09-05T09:39:36.999749Z"
        },
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = deeplob(3)\n",
        "#model.to(device)"
      ],
      "metadata": {
        "id": "aO6a-XgB7tRk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkbH53NFMy3-",
        "outputId": "ad1f04fe-bc86-484e-a4c5-1140ba8e15a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "deeplob(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.01)\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
              "    (7): LeakyReLU(negative_slope=0.01)\n",
              "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
              "    (1): Tanh()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
              "    (4): Tanh()\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
              "    (7): Tanh()\n",
              "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(32, 32, kernel_size=(1, 10), stride=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.01)\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
              "    (7): LeakyReLU(negative_slope=0.01)\n",
              "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (inp1): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
              "    (4): LeakyReLU(negative_slope=0.01)\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (inp2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
              "    (4): LeakyReLU(negative_slope=0.01)\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (inp3): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
              "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
              "    (2): LeakyReLU(negative_slope=0.01)\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (lstm): LSTM(192, 64, batch_first=True)\n",
              "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (1, 1, 100, 40))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvOVMx-OVqMt",
        "outputId": "120cf815-f221-4dc4-b9da-40033062a350"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "deeplob                                  [1, 3]                    --\n",
              "├─Sequential: 1-1                        [1, 32, 94, 20]           --\n",
              "│    └─Conv2d: 2-1                       [1, 32, 100, 20]          96\n",
              "│    └─LeakyReLU: 2-2                    [1, 32, 100, 20]          --\n",
              "│    └─BatchNorm2d: 2-3                  [1, 32, 100, 20]          64\n",
              "│    └─Conv2d: 2-4                       [1, 32, 97, 20]           4,128\n",
              "│    └─LeakyReLU: 2-5                    [1, 32, 97, 20]           --\n",
              "│    └─BatchNorm2d: 2-6                  [1, 32, 97, 20]           64\n",
              "│    └─Conv2d: 2-7                       [1, 32, 94, 20]           4,128\n",
              "│    └─LeakyReLU: 2-8                    [1, 32, 94, 20]           --\n",
              "│    └─BatchNorm2d: 2-9                  [1, 32, 94, 20]           64\n",
              "├─Sequential: 1-2                        [1, 32, 88, 10]           --\n",
              "│    └─Conv2d: 2-10                      [1, 32, 94, 10]           2,080\n",
              "│    └─Tanh: 2-11                        [1, 32, 94, 10]           --\n",
              "│    └─BatchNorm2d: 2-12                 [1, 32, 94, 10]           64\n",
              "│    └─Conv2d: 2-13                      [1, 32, 91, 10]           4,128\n",
              "│    └─Tanh: 2-14                        [1, 32, 91, 10]           --\n",
              "│    └─BatchNorm2d: 2-15                 [1, 32, 91, 10]           64\n",
              "│    └─Conv2d: 2-16                      [1, 32, 88, 10]           4,128\n",
              "│    └─Tanh: 2-17                        [1, 32, 88, 10]           --\n",
              "│    └─BatchNorm2d: 2-18                 [1, 32, 88, 10]           64\n",
              "├─Sequential: 1-3                        [1, 32, 82, 1]            --\n",
              "│    └─Conv2d: 2-19                      [1, 32, 88, 1]            10,272\n",
              "│    └─LeakyReLU: 2-20                   [1, 32, 88, 1]            --\n",
              "│    └─BatchNorm2d: 2-21                 [1, 32, 88, 1]            64\n",
              "│    └─Conv2d: 2-22                      [1, 32, 85, 1]            4,128\n",
              "│    └─LeakyReLU: 2-23                   [1, 32, 85, 1]            --\n",
              "│    └─BatchNorm2d: 2-24                 [1, 32, 85, 1]            64\n",
              "│    └─Conv2d: 2-25                      [1, 32, 82, 1]            4,128\n",
              "│    └─LeakyReLU: 2-26                   [1, 32, 82, 1]            --\n",
              "│    └─BatchNorm2d: 2-27                 [1, 32, 82, 1]            64\n",
              "├─Sequential: 1-4                        [1, 64, 82, 1]            --\n",
              "│    └─Conv2d: 2-28                      [1, 64, 82, 1]            2,112\n",
              "│    └─LeakyReLU: 2-29                   [1, 64, 82, 1]            --\n",
              "│    └─BatchNorm2d: 2-30                 [1, 64, 82, 1]            128\n",
              "│    └─Conv2d: 2-31                      [1, 64, 82, 1]            12,352\n",
              "│    └─LeakyReLU: 2-32                   [1, 64, 82, 1]            --\n",
              "│    └─BatchNorm2d: 2-33                 [1, 64, 82, 1]            128\n",
              "├─Sequential: 1-5                        [1, 64, 82, 1]            --\n",
              "│    └─Conv2d: 2-34                      [1, 64, 82, 1]            2,112\n",
              "│    └─LeakyReLU: 2-35                   [1, 64, 82, 1]            --\n",
              "│    └─BatchNorm2d: 2-36                 [1, 64, 82, 1]            128\n",
              "│    └─Conv2d: 2-37                      [1, 64, 82, 1]            20,544\n",
              "│    └─LeakyReLU: 2-38                   [1, 64, 82, 1]            --\n",
              "│    └─BatchNorm2d: 2-39                 [1, 64, 82, 1]            128\n",
              "├─Sequential: 1-6                        [1, 64, 82, 1]            --\n",
              "│    └─MaxPool2d: 2-40                   [1, 32, 82, 1]            --\n",
              "│    └─Conv2d: 2-41                      [1, 64, 82, 1]            2,112\n",
              "│    └─LeakyReLU: 2-42                   [1, 64, 82, 1]            --\n",
              "│    └─BatchNorm2d: 2-43                 [1, 64, 82, 1]            128\n",
              "├─LSTM: 1-7                              [1, 82, 64]               66,048\n",
              "├─Linear: 1-8                            [1, 3]                    195\n",
              "==========================================================================================\n",
              "Total params: 143,907\n",
              "Trainable params: 143,907\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 35.53\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 4.97\n",
              "Params size (MB): 0.58\n",
              "Estimated Total Size (MB): 5.56\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "wOZGR6lGF9QG",
        "execution": {
          "iopub.status.busy": "2023-09-05T09:39:37.724224Z",
          "iopub.execute_input": "2023-09-05T09:39:37.72482Z",
          "iopub.status.idle": "2023-09-05T09:39:37.733677Z",
          "shell.execute_reply.started": "2023-09-05T09:39:37.724784Z",
          "shell.execute_reply": "2023-09-05T09:39:37.732773Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to encapsulate the training loop\n",
        "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "\n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "    best_test_loss = np.inf\n",
        "    best_test_epoch = 0\n",
        "\n",
        "    for it in tqdm(range(epochs)):\n",
        "\n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "        for inputs, targets in train_loader:\n",
        "            # move data to GPU\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "            # print(\"inputs.shape:\", inputs.shape)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            # print(\"about to get model output\")\n",
        "            outputs = model(inputs)\n",
        "            # print(\"done getting model output\")\n",
        "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # Backward and optimize\n",
        "            # print(\"about to optimize\")\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "        # Get train loss and test loss\n",
        "        train_loss = np.mean(train_loss) # a little misleading\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss.append(loss.item())\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "\n",
        "        if test_loss < best_test_loss:\n",
        "            torch.save(model, '/content/download/MyDrive/best_val_model_pytorch')\n",
        "            best_test_loss = test_loss\n",
        "            best_test_epoch = it\n",
        "            print('model saved')\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
        "\n",
        "    return train_losses, test_losses"
      ],
      "metadata": {
        "id": "OUohd29QajuR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = batch_gd(model, criterion, optimizer, train_loader, val_loader, epochs=50)"
      ],
      "metadata": {
        "id": "vL_V0uf3eno8",
        "execution": {
          "iopub.status.busy": "2023-09-05T09:41:05.232727Z",
          "iopub.execute_input": "2023-09-05T09:41:05.233295Z",
          "iopub.status.idle": "2023-09-05T12:03:19.36192Z",
          "shell.execute_reply.started": "2023-09-05T09:41:05.233248Z",
          "shell.execute_reply": "2023-09-05T12:03:19.359878Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc8e869-eefa-4a54-8d13-cd8f333c23a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "  2%|▏         | 1/50 [07:38<6:14:31, 458.60s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved\n",
            "Epoch 1/50, Train Loss: 0.9041,           Validation Loss: 0.9705, Duration: 0:07:38.595991, Best Val Epoch: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 2/50 [15:17<6:07:01, 458.78s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50, Train Loss: 0.8788,           Validation Loss: 0.9830, Duration: 0:07:38.909224, Best Val Epoch: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 3/50 [22:56<5:59:25, 458.84s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/50, Train Loss: 0.8670,           Validation Loss: 1.0995, Duration: 0:07:38.909273, Best Val Epoch: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 4/50 [30:33<5:51:14, 458.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/50, Train Loss: 0.8528,           Validation Loss: 1.2014, Duration: 0:07:37.049196, Best Val Epoch: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 5/50 [38:11<5:43:40, 458.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/50, Train Loss: 0.8372,           Validation Loss: 1.0000, Duration: 0:07:38.389241, Best Val Epoch: 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 6/50 [45:48<5:35:40, 457.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/50, Train Loss: 0.8217,           Validation Loss: 1.0641, Duration: 0:07:36.774915, Best Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [53:28<5:28:36, 458.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50, Train Loss: 0.8089,           Validation Loss: 1.0223, Duration: 0:07:40.116336, Best Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [1:01:07<5:20:56, 458.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50, Train Loss: 0.7978,           Validation Loss: 1.0208, Duration: 0:07:38.441790, Best Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [1:08:44<5:13:01, 458.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50, Train Loss: 0.7884,           Validation Loss: 1.0278, Duration: 0:07:37.190254, Best Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [1:16:21<5:05:08, 457.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50, Train Loss: 0.7803,           Validation Loss: 1.0360, Duration: 0:07:36.875219, Best Val Epoch: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],label='Train Loss')\n",
        "plt.plot(history.history['val_loss'],label='Validation Loss')\n",
        "plt.title('Loss Per epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-05T12:03:19.656594Z",
          "iopub.execute_input": "2023-09-05T12:03:19.656941Z",
          "iopub.status.idle": "2023-09-05T12:03:19.914659Z",
          "shell.execute_reply.started": "2023-09-05T12:03:19.656898Z",
          "shell.execute_reply": "2023-09-05T12:03:19.913661Z"
        },
        "trusted": true,
        "id": "Yt73JUJxUkca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label='Validation Accuracy')\n",
        "plt.title('Accuracy Per epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-05T13:34:56.073071Z",
          "iopub.execute_input": "2023-09-05T13:34:56.073438Z",
          "iopub.status.idle": "2023-09-05T13:34:56.527006Z",
          "shell.execute_reply.started": "2023-09-05T13:34:56.073405Z",
          "shell.execute_reply": "2023-09-05T13:34:56.52468Z"
        },
        "trusted": true,
        "id": "m-xvr_qdUkcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "DrxGhQpZMuSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/download/MyDrive/best_val_model_pytorch')\n",
        "\n",
        "all_targets = []\n",
        "all_predictions = []\n",
        "\n",
        "for inputs, targets in test_loader:\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Get prediction\n",
        "    # torch.max returns both max and argmax\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    all_targets.append(targets.cpu().numpy())\n",
        "    all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "all_targets = np.concatenate(all_targets)\n",
        "all_predictions = np.concatenate(all_predictions)"
      ],
      "metadata": {
        "id": "PiK1_S3FCblH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
        "print(classification_report(all_targets, all_predictions, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtHXOHS1CceU",
        "outputId": "798655cf-5fea-4e0c-f825-69774b7daceb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score: 0.5342887251431881\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5248    0.6477    0.5798     84287\n",
            "           1     0.5713    0.4391    0.4966     80711\n",
            "           2     0.5184    0.5118    0.5151     83626\n",
            "\n",
            "    accuracy                         0.5343    248624\n",
            "   macro avg     0.5382    0.5329    0.5305    248624\n",
            "weighted avg     0.5377    0.5343    0.5310    248624\n",
            "\n"
          ]
        }
      ]
    }
  ]
}